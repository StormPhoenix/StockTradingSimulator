# 通用时间序列多周期聚合系统设计文档

## 文档信息

- **版本**: 1.0
- **创建日期**: 2026-01-26
- **状态**: 设计方案
- **适用场景**: 通用时间序列数据的多周期聚合

---

## 目录

- [1. 概述](#1-概述)
- [2. 设计目标与约束](#2-设计目标与约束)
- [3. 核心概念](#3-核心概念)
- [4. 数据结构设计](#4-数据结构设计)
- [5. 聚合策略](#5-聚合策略)
- [6. 数据生命周期管理](#6-数据生命周期管理)
- [7. 存储架构](#7-存储架构)
- [8. 核心接口设计](#8-核心接口设计)
- [9. 完整数据流](#9-完整数据流)
- [10. 技术要点](#10-技术要点)

---

## 1. 概述

### 1.1 设计背景

时间序列数据聚合是数据分析的核心需求。以股票市场 K 线为例，原始数据是随时间变化的价格和成交量序列，需要按照不同的时间周期统计：
- 价格的上下区间（high/low）
- 周期起始和结束时的值（open/close）
- 成交量总和
- 加权平均价格（VWAP）

本方案设计一个通用的、应用无关的时间序列多周期聚合系统，能够支持任意类型的时间序列数据。

### 1.2 设计特点

- **通用性**: 不依赖任何具体应用场景
- **灵活性**: 支持任意时间粒度和聚合指标
- **高性能**: 实时聚合，查询延迟 < 100ms
- **智能管理**: 自动剔除原始数据，优化存储

### 1.3 应用场景

- 金融数据：股票、加密货币、期货的 K 线聚合
- 物联网：传感器数据的周期统计
- 监控系统：性能指标的周期分析
- 日志分析：访问日志的时间聚合

---

## 2. 设计目标与约束

### 2.1 功能目标

| 目标 | 描述 |
|-----|------|
| 多粒度支持 | 支持 1m, 5m, 15m, 30m, 60m, 120m, 1d, 5d, 20d, 120d, 250d |
| 多指标聚合 | 支持 open, high, low, close, volume, vwap 等指标 |
| 实时处理 | 实时数据写入，延迟 < 100ms |
| 智能存储 | 自动剔除原始数据，保留聚合数据 |
| 高效查询 | 支持跨周期查询优化 |

### 2.2 技术约束

| 约束项 | 要求 |
|--------|------|
| 实时性 | 端到端延迟 < 100ms，容忍度不超过 0.1 秒 |
| 查询范围 | 固定的预定义周期，不支持多序列联合查询、跨符号查询 |
| 数据修正 | 原始数据不会被修正回填，历史数据变化需重建聚合 |
| 计算资源 | 无限制，无需分布式支持 |
| 存储方案 | 存储无关设计，暂不指定具体存储后端 |

### 2.3 业务约束

1. **时间窗口对齐**: 严格对齐到自然边界
2. **缺失数据处理**:
   - 连续值（如价格）：用上一周期的 close 作为当前 open
   - 频率值（如成交量）：值为 0
3. **数据保留**:
   - 原始数据（< 最小粒度）：可在聚合完成后剔除
   - 聚合数据（≥ 最小粒度）：永久保留
4. **跨周期查询**: 采用更粗粒度的预聚合数据优化性能

---

## 3. 核心概念

### 3.1 数据序列类型

#### 连续值序列（CONTINUOUS）

定义: 数据值在时间上连续变化，无数据时保持上一值。

**特点**:
- 任意时刻都有有效值
- 缺失时用前值填充
- 适合价格、温度、汇率等指标

**缺失数据处理**: 用上一周期的 close 作为当前 open

#### 离散/频率值序列（DISCRETE）

定义: 数据值表示事件发生的频率或计数，无事件时值为 0。

**特点**:
- 有事件时才有值
- 无事件时值为 0
- 适合成交量、成交笔数、请求数等指标

**缺失数据处理**: 周期内无交易则值为 0

### 3.2 聚合粒度（Granularity）

定义: 时间聚合的基本单位。

#### 预定义粒度列表

| 粒度 | 描述 | 使用场景 |
|-----|------|---------|
| 1m | 1 分钟 | 短期交易、实时监控 |
| 5m | 5 分钟 | 日内交易分析 |
| 15m | 15 分钟 | 短期趋势分析 |
| 30m | 30 分钟 | 中期趋势分析 |
| 60m | 1 小时 | 日内波段操作 |
| 120m | 2 小时 | 日内趋势 |
| 1d | 1 天 | 中长期分析 |
| 5d | 5 天 | 中期策略 |
| 20d | 20 天 | 中长期策略 |
| 120d | 120 天 | 长期趋势 |
| 250d | 250 天 | 年度分析 |

#### 最小粒度

- **定义**: 1m 是系统的最小预聚合粒度
- **作用**:
  - 作为原始数据和聚合数据的分界线
  - 小于 1m 的数据视为原始数据，可剔除
  - 大于等于 1m 的数据视为聚合数据，永久保留

#### 粒度对齐

严格对齐到自然时间边界。

**示例**:
- 1m 粒度: `00:00:00 - 00:01:00`, `00:01:00 - 00:02:00`, ...
- 5m 粒度: `00:00:00 - 00:05:00`, `00:05:00 - 00:10:00`, ...
- 1d 粒度: `2024-01-26 00:00:00 - 2024-01-27 00:00:00`, ...

### 3.3 聚合窗口（Aggregation Window）

定义: 按指定粒度划分的时间区间，用于聚合计算。

**属性**:
- `startTime`: 窗口开始时间（包含）
- `endTime`: 窗口结束时间（不包含）
- `granularity`: 聚合粒度
- `status`: 窗口状态（活跃、关闭中、已关闭）

**状态机**:

```
Active（活跃）
  ↓
  - 实时接收数据
  - 增量聚合
  ↓（到达 endTime）
Closing（关闭中）
  ↓
  - 停止接收数据
  - 持久化聚合结果
  ↓（持久化完成）
Closed（已关闭）
  ↓
  - 数据可查询
  - 原始数据可剔除（若 >= 最小粒度）
```

### 3.4 粒度依赖关系

定义: 粗粒度的聚合依赖于细粒度的聚合结果。

**依赖链**:

```
原始数据（< 1m）
  ↓ 聚合
1m（最小粒度）
  ↓ 聚合
5m
  ↓ 聚合
15m
  ↓ 聚合
30m
  ↓ 聚合
60m
  ↓ 聚合
120m
  ↓ 聚合
1d
  ↓ 聚合
5d
  ↓ 聚合
20d
  ↓ 聚合
120d
  ↓ 聚合
250d
```

**特点**:
- 粗粒度不直接使用原始数据
- 粗粒度基于相邻的细粒度聚合结果计算
- 优化聚合性能，避免重复计算

---

## 4. 数据结构设计

### 4.1 核心数据结构

#### 数据点（DataPoint）

最细粒度的原始数据点。

**属性**:
- `timestamp`: 毫秒级时间戳
- `seriesId`: 序列唯一标识
- `value`: 数据值
- `metadata`: 可选元数据

**用途**:
- 实时数据推送
- 增量聚合输入
- 临时存储，聚合完成后可剔除

#### 聚合点（AggregatedPoint）

聚合窗口的计算结果。

**属性**:
- `startTime`: 窗口开始时间
- `endTime`: 窗口结束时间
- `seriesId`: 序列标识
- `granularity`: 聚合粒度
- `dataCount`: 窗口内原始数据点数量（0 表示无数据）
- `metrics`: 聚合指标字典

**metrics 示例**:
```json
{
  "open": 100.5,
  "high": 105.2,
  "low": 99.8,
  "close": 103.1,
  "volume": 15000,
  "vwap": 102.5
}
```

**用途**:
- 查询结果返回
- 更粗粒度聚合的输入
- 永久存储，不可剔除

#### 序列定义（SeriesDefinition）

序列的元数据和配置。

**属性**:
- `seriesId`: 序列唯一标识
- `name`: 显示名称
- `seriesType`: 序列类型（CONTINUOUS / DISCRETE）
- `missingDataStrategy`: 缺失数据处理策略
- `metrics`: 需要计算的指标列表
- `relatedSeries`: 关联序列（用于 VWAP 等复合指标）

**示例**:
```json
{
  "seriesId": "AAPL.price",
  "name": "Apple Stock Price",
  "seriesType": "CONTINUOUS",
  "missingDataStrategy": "PREVIOUS_CLOSE",
  "metrics": ["open", "high", "low", "close", "vwap"],
  "relatedSeries": {
    "vwap": "AAPL.volume"
  }
}
```

### 4.2 聚合指标系统

#### 指标定义（MetricDefinition）

聚合指标的元数据。

**属性**:
- `name`: 指标名称
- `description`: 指标描述
- `requiredSeriesType`: 适用的序列类型
- `aggregationFunction`: 聚合函数
- `dependencies`: 依赖的其他指标

#### 核心指标列表

| 指标名 | 描述 | 适用类型 | 说明 |
|-------|------|---------|------|
| open | 周期开始时的值 | CONTINUOUS | 窗口内第一个有效数据点的值 |
| close | 周期结束时的值 | CONTINUOUS | 窗口内最后一个有效数据点的值 |
| high | 周期内的最高值 | CONTINUOUS | 窗口内所有数据点的最大值 |
| low | 周期内的最低值 | CONTINUOUS | 窗口内所有数据点的最小值 |
| sum | 周期内值的总和 | DISCRETE | 窗口内所有数据点的累加 |
| count | 周期内数据点数量 | DISCRETE | 窗口内有效数据点的计数 |
| vwap | 成交量加权平均价格 | CONTINUOUS | 价格×成交量的加权平均 |

#### 指标依赖

某些指标的计算依赖其他序列。

**示例**: VWAP 计算需要价格和成交量两个序列
- 价格序列：提供 price × volume 的乘积
- 成交量序列：提供 volume 的总和
- VWAP = sum(price × volume) / sum(volume)

#### 指标扩展机制

支持动态注册自定义指标。

**流程**:
1. 定义指标聚合函数
2. 注册到指标系统
3. 在序列配置中启用
4. 自动参与聚合计算

### 4.3 活跃窗口（ActiveWindow）

内存中当前活跃的聚合窗口。

**属性**:
- `windowId`: 窗口唯一标识
- `seriesId`: 序列标识
- `granularity`: 聚合粒度
- `startTime`: 窗口开始时间
- `endTime`: 窗口结束时间
- `dataPoints`: 原始数据点缓冲区
- `aggregates`: 实时聚合状态（累加器）

**aggregates 结构**:
```json
{
  "open": {
    "value": 100.5,
    "dataCount": 1500,
    "accumulator": { ... }
  },
  "high": {
    "value": 105.2,
    "dataCount": 1500,
    "accumulator": { ... }
  },
  "low": { ... },
  "close": { ... },
  "volume": { ... },
  "vwap": { ... }
}
```

**特点**:
- 完全在内存中
- 支持增量更新
- 查询延迟 < 1ms

---

## 5. 聚合策略

### 5.1 增量聚合

#### 核心思想

维护累加器，避免全量重算。

**传统聚合**（低效）:
```
窗口收到新数据点 → 遍历所有历史点 → 重新计算所有指标
```

**增量聚合**（高效）:
```
窗口收到新数据点 → 更新累加器 → 立即得到结果
```

#### 累加器设计

每个指标对应一个累加器，支持增量更新。

**累加器接口**:
- `init()`: 初始化累加器
- `add(dataPoint)`: 添加数据点
- `getResult()`: 获取当前结果
- `merge(other)`: 合并两个累加器（用于窗口合并）

#### 累加器实现示例

##### 最大值累加器（MaxAggregator）

**逻辑**:
1. 初始化: max = null
2. 添加: max = max(max, newValue)
3. 结果: max

**特点**: O(1) 更新，无需遍历

##### 成交量加权平均累加器（VWAPAggregator）

**逻辑**:
1. 初始化: sumPriceVolume = 0, sumVolume = 0
2. 添加:
   - sumPriceVolume += price × volume
   - sumVolume += volume
3. 结果: sumPriceVolume / sumVolume

**特点**: 需要两个序列（价格和成交量）

### 5.2 聚合流程

#### 写入流程

```
实时数据到达
  ↓
1. 写入原始数据存储
  ↓
2. 写入内存缓冲区（当前活跃窗口）
  ↓
3. 立即触发该窗口的增量聚合
  ↓
4. 更新预聚合结果
  ↓
5. 如果窗口结束，刷新到持久化存储

总耗时: < 100ms
```

#### 窗口切换

**时间线示例**（1m 粒度）:

```
10:24:59.500
  ↓
  10:24 窗口: ACTIVE 状态
  10:25 窗口: 不存在
  ↓
10:25:00.000
  ↓
  检测到窗口切换
  10:24 窗口: ACTIVE → CLOSING
  10:25 窗口: 创建并设为 ACTIVE
  异步触发 10:24 窗口持久化
  ↓
10:25:00.100
  ↓
  新数据到达，直接写入 10:25 窗口
  10:24 窗口: CLOSING → CLOSED（持久化完成）
  10:24 数据已可查询
```

#### 批量持久化优化

**策略**:
- 单窗口持久化：独立事务
- 批量插入：一次持久化多个窗口
- 异步写入：使用写入队列
- 预写日志：先写 WAL（Write-Ahead Log）

**持久化时机**:
- 窗口结束立即触发
- 或者每 50ms 批量触发一次
- 或者累积达到一定数量触发一次

**保证**:
- 单窗口持久化延迟 < 100ms
- 查询时数据一定可用

### 5.3 跨粒度聚合

#### 粒度层级

所有预定义粒度按从小到大排序：

```
Level 0:  1m
Level 1:  5m
Level 2:  15m
Level 3:  30m
Level 4:  60m
Level 5:  120m
Level 6:  1d
Level 7:  5d
Level 8:  20d
Level 9:  120d
Level 10: 250d
```

#### 聚合链构建

**目标**: 聚合 1 天数据，目标粒度 5m

**链条**:
```
Level 0 (1m): 需要 1440 个窗口
Level 1 (5m): 需要 288 个窗口
```

**执行顺序**:
1. 先确保所有 1m 窗口聚合完成
2. 然后聚合 5m 窗口（使用 1m 的结果）

#### 自动聚合触发

**规则**:
- 细粒度窗口完成 → 触发依赖的粗粒度聚合
- 批量触发：避免频繁触发

**示例**:
```
1m 窗口 10:00 完成
  ↓
  检查 5m 窗口（10:00-10:05）
  - 如果 5m 的 5 个 1m 子窗口都完成
  - 触发 5m 窗口聚合
```

### 5.4 缺失数据填充

#### 填充逻辑

根据序列类型采用不同的填充策略。

**连续值序列**:
```json
// 周期内无数据
{
  "startTime": "2024-01-26T10:00:00.000Z",
  "endTime": "2024-01-26T10:01:00.000Z",
  "dataCount": 0,
  "metrics": {
    "open": 150.0,    // 上一周期的 close
    "high": 150.0,
    "low": 150.0,
    "close": 150.0
  }
}
```

**频率值序列**:
```json
// 周期内无数据
{
  "startTime": "2024-01-26T10:00:00.000Z",
  "endTime": "2024-01-26T10:01:00.000Z",
  "dataCount": 0,
  "metrics": {
    "sum": 0,      // 值为 0
    "count": 0
  }
}
```

#### Gap 识别

**示例**:
```
查询 10:00 - 11:00 的 5m 数据

返回数据:
- 10:00, 10:05, 10:10, 10:15, 10:20, 10:25, 10:30
- 缺少 10:35, 10:40, 10:45, 10:50, 10:55

识别为 gap，根据配置填充
```

---

## 6. 数据生命周期管理

### 6.1 数据分层

#### Level 0: 原始数据（细粒度）

**特征**:
- 粒度: < 1m（如秒、毫秒）
- 生命周期: 临时
- 用途: 聚合最小粒度数据

**存储**: 临时存储，可剔除

#### Level 1: 最小粒度聚合数据

**特征**:
- 粒度: = 1m
- 生命周期: 永久
- 用途: 查询细粒度数据、聚合粗粒度数据

**存储**: 永久存储，不可剔除

#### Level 2-N: 粗粒度聚合数据

**特征**:
- 粒度: > 1m（5m, 15m, ..., 250d）
- 生命周期: 永久
- 用途: 查询历史数据

**存储**: 永久存储，不可剔除

### 6.2 数据保留策略

#### 原始数据剔除

**剔除条件**:
1. 最小粒度（1m）的对应窗口已聚合完成
2. 已经过安全缓冲期（60 秒）
3. 没有依赖这些原始数据的进行中任务

**剔除时机**:
- 定时扫描（每分钟）
- 识别符合条件的数据范围
- 执行剔除任务

**缓冲期意义**:
- 确保聚合结果稳定
- 支持可能的聚合重试
- 避免并发冲突

#### 聚合数据保留

**最小粒度数据**: 永久保留
- 作为细粒度查询的基础
- 作为粗粒度聚合的数据源

**粗粒度数据**: 永久保留
- 优化历史数据查询性能
- 支持跨周期查询优化

### 6.3 数据保留矩阵

| 数据层级 | 粒度范围 | 保留策略 | 剔除时机 |
|---------|----------|---------|---------|
| Level 0 | < 1m | 临时 | 1m 聚合完成后 + 60 秒缓冲 |
| Level 1 | = 1m | 永久 | 永不剔除 |
| Level 2-N | > 1m | 永久 | 永不剔除 |

### 6.4 剔除任务调度

#### 剔除任务结构

**属性**:
- `taskId`: 任务唯一标识
- `seriesId`: 序列标识
- `targetRange`: 要剔除的时间范围
- `granularitiesToPurge`: 仅 < 最小粒度的原始数据
- `scheduledAt`: 调度时间
- `priority`: 优先级（HIGH / NORMAL / LOW）

#### 调度策略

**扫描周期**: 每分钟

**优先级计算**:
- 基于数据量
- 基于数据年龄
- 较早的数据优先剔除

**并发控制**:
- 最大并发剔除任务数（可配置）
- 避免存储压力过大

### 6.5 历史数据重建

#### 重建触发场景

1. **数据替换**: 历史数据被完整替换
2. **指标变更**: 序列配置修改（添加/删除指标）
3. **手动触发**: 管理员手动重建

#### 重建流程

```
1. 锁定目标序列
  ↓
2. 标记需要重建的时间范围
  ↓
3. 删除指定范围的预聚合数据
  ↓
4. 从原始数据重新计算聚合
  ↓
5. 批量写入新的预聚合结果
  ↓
6. 释放序列锁
  ↓
7. 更新聚合状态
```

#### 优化策略

**增量重建**:
- 只重建受影响的时间范围
- 分析数据变化
- 识别需要重建的窗口

**分批处理**:
- 大范围分批处理
- 避免长时间锁定
- 进度可查询，支持取消

---

## 7. 存储架构

### 7.1 分层存储

#### 实时层级（Level 0: 活跃窗口）

**特点**:
- 完全在内存中
- 实时增量更新
- 查询延迟 < 1ms
- 数量: 约 11 个粒度 × 序列数

**示例**:
```
AAPL.price_1m:  10:25:00 - 10:26:00  （活跃）
AAPL.price_5m:  10:25:00 - 10:30:00  （活跃）
AAPL.price_1d:  2024-01-26 00:00:00 - 2024-01-27 00:00:00  （活跃）
...
```

#### 热数据层级（Level 1: 最近数据）

**特点**:
- 存储位置: 数据库 + 缓存（Redis/Memcached）
- 范围: 最近 30 天（可配置）
- 粒度: 所有预定义粒度
- 查询延迟: ~10ms

#### 冷数据层级（Level 2: 历史数据）

**特点**:
- 存储位置: 数据库
- 范围: 30 天以前的所有数据
- 粒度: 所有预定义粒度
- 查询延迟: ~50-100ms

### 7.2 存储无关抽象

#### 抽象接口

**原始数据操作**:
- `writeRawData`: 写入单个原始数据点
- `writeRawDataBatch`: 批量写入原始数据
- `readRawData`: 读取原始数据范围
- `deleteRawData`: 删除原始数据范围

**聚合数据操作**:
- `writeAggregatedData`: 写入单个聚合点
- `writeAggregatedDataBatch`: 批量写入聚合点
- `readAggregatedData`: 读取聚合数据范围
- `deleteAggregatedData`: 删除聚合数据范围

**状态管理**:
- `writeWindowStatus`: 写入窗口聚合状态
- `readWindowStatus`: 读取窗口状态
- `readWindowStatusInRange`: 批量读取状态

**元数据**:
- `getSeriesInfo`: 获取序列信息
- `getAllSeries`: 获取所有序列

#### 序列信息

**属性**:
- `seriesId`: 序列标识
- `seriesType`: 序列类型
- `createdAt`: 创建时间
- `lastUpdated`: 最后更新时间
- `rawDataStats`: 原始数据统计
- `aggregatedStats`: 聚合数据统计

---

## 8. 核心接口设计

### 8.1 写入接口

#### 添加原始数据点

**接口**:
```
addDataPoint(seriesId, dataPoint, triggerAggregation?)
```

**参数**:
- `seriesId`: 序列标识
- `dataPoint`: 数据点对象
- `triggerAggregation`: 是否触发预聚合（默认 true）

**返回**: 无

#### 批量添加原始数据

**接口**:
```
addDataPointBatch(seriesId, dataPoints, triggerAggregation?)
```

**参数**:
- `seriesId`: 序列标识
- `dataPoints`: 数据点数组
- `triggerAggregation`: 是否触发预聚合（默认 true）

**返回**: 无

### 8.2 查询接口

#### 查询聚合数据

**接口**:
```
queryAggregatedData(options)
```

**参数**:
- `seriesId`: 序列标识（单个或多个）
- `granularity`: 聚合粒度
- `startTime`: 查询开始时间
- `endTime`: 查询结束时间
- `metrics`: 指定返回的指标（可选）
- `fillMissingData`: 是否填充缺失数据（默认 false）
- `optimizeGranularity`: 是否自动优化粒度（默认 true）
- `includeMetadata`: 是否包含元数据（默认 false）

**返回**:
```json
{
  "seriesId": "AAPL.price",
  "granularity": { "value": 1, "unit": "m" },
  "startTime": 1643184000000,
  "endTime": 1643187600000,
  "points": [
    {
      "startTime": 1643184000000,
      "endTime": 1643184060000,
      "dataCount": 100,
      "metrics": { ... }
    },
    ...
  ],
  "actualGranularity": { "value": 1, "unit": "m" },
  "metadata": { ... }
}
```

#### 自动粒度优化

**场景**: 查询大范围数据，自动选择更粗粒度

**示例**:
```
查询 250 天数据，请求 1m
→ 自动选择 1d 预聚合数据
→ 返回 250 个数据点（而非 250×24×60 = 360,000 个）

查询 1 天数据，请求 1m
→ 查询 1m 预聚合数据
→ 返回 1440 个数据点
```

### 8.3 聚合管理接口

#### 手动触发预聚合

**接口**:
```
preaggregate(options)
```

**参数**:
- `seriesId`: 序列标识
- `granularity`: 聚合粒度
- `startTime`: 聚合开始时间
- `endTime`: 聚合结束时间
- `forceRecalculate`: 是否强制重新计算（默认 false）

**返回**: 无

#### 获取聚合状态

**接口**:
```
getAggregationStatus(seriesId, granularity?, startTime?, endTime?)
```

**参数**:
- `seriesId`: 序列标识
- `granularity`: 可选，指定粒度
- `startTime`: 可选，查询范围开始
- `endTime`: 可选，查询范围结束

**返回**: 窗口聚合状态数组

### 8.4 数据管理接口

#### 创建序列

**接口**:
```
createSeries(seriesDefinition)
```

**参数**: 序列定义对象

**返回**: 序列标识

#### 更新序列配置

**接口**:
```
updateSeries(seriesId, updates)
```

**参数**:
- `seriesId`: 序列标识
- `updates`: 更新的字段（metrics, relatedSeries 等）

**返回**: 无

#### 删除序列

**接口**:
```
deleteSeries(seriesId, deleteData?)
```

**参数**:
- `seriesId`: 序列标识
- `deleteData`: 是否删除数据（默认 true）

**返回**: 无

### 8.5 数据剔除接口

#### 创建剔除任务

**接口**:
```
schedulePurge(task)
```

**参数**: 剔除任务对象

**返回**: 任务标识

#### 执行剔除任务

**接口**:
```
executePurge(taskId)
```

**参数**: 任务标识

**返回**: 剔除结果对象

#### 获取剔除结果

**接口**:
```
getPurgeResult(taskId)
```

**参数**: 任务标识

**返回**: 剔除结果对象

---

## 9. 完整数据流

### 9.1 实时数据流

```
┌────────────┐    ┌────────────┐    ┌────────────┐
│   数据源    │──→│   接收器    │──→│   解析器    │
└────────────┘    └────────────┘    └────────────┘
                                  ↓
                         ┌──────────────────┐
                         │   写入队列       │
                         └──────────────────┘
                                  ↓
                         ┌──────────────────┐
                         │  原始数据存储   │
                         │  (Level 0)      │
                         └──────────────────┘
                                  ↓
                         ┌──────────────────┐
                         │  内存窗口管理器  │
                         │  (11个粒度)     │
                         └──────────────────┘
                                  ↓
                         ┌──────────────────┐
                         │  增量聚合引擎   │
                         └──────────────────┘
                                  ↓
                         ┌──────────────────┐
                         │  预聚合存储     │
                         │  (所有粒度)     │
                         └──────────────────┘
                                  ↓
                         ┌──────────────────┐
                         │   查询服务       │
                         └──────────────────┘
                                  ↓
                         ┌──────────────────┐
                         │    客户端        │
                         └──────────────────┘
```

### 9.2 聚合数据流

```
原始数据（Level 0）
  ↓
  [1m 窗口聚合]
  ↓
  1m 聚合数据（Level 1）
  ↓
  [5m 窗口聚合]
  ↓
  5m 聚合数据（Level 2）
  ↓
  [15m 窗口聚合]
  ↓
  15m 聚合数据（Level 3）
  ↓
  ...
  ↓
  250d 聚合数据（Level 10）
```

### 9.3 查询数据流

```
查询请求
  ↓
分析查询范围和粒度
  ↓
选择查询路径:
  ├─ Level 0（活跃窗口）< 1ms
  ├─ Level 1（热数据）  ~10ms
  └─ Level 2（冷数据）  ~50ms
  ↓
并行查询各层级
  ↓
合并查询结果
  ↓
按 startTime 排序
  ↓
填充 gaps（根据配置）
  ↓
返回完整结果
  ↓
总查询时间: < 100ms
```

### 9.4 数据剔除流

```
定时触发（每分钟）
  ↓
扫描所有序列
  ↓
检查聚合状态
  ↓
判断剔除条件:
  ├─ 最小粒度聚合完成？
  ├─ 已经过缓冲期（60秒）？
  └─ 没有进行中的依赖任务？
  ↓
符合条件 → 创建剔除任务
  ↓
执行剔除任务
  ↓
删除 Level 0 的原始数据
  ↓
保留 Level 1 及以上的聚合数据
  ↓
记录删除结果
  ↓
释放存储空间
```

### 9.5 各阶段耗时

| 阶段 | 目标延迟 | 实际估计 |
|------|---------|---------|
| 数据接收 | < 100ms | < 1ms |
| 队列写入 | < 100ms | < 1ms |
| 原始数据存储 | < 100ms | < 10ms |
| 内存窗口更新 | < 100ms | < 1ms |
| 增量聚合 | < 100ms | < 5ms |
| 预聚合更新 | < 100ms | < 10ms |
| 总写入延迟 | < 100ms | < 30ms |

| 查询类型 | 目标延迟 | 实际估计 |
|---------|---------|---------|
| 实时查询（当前窗口） | < 100ms | < 1ms |
| 热数据查询 | < 100ms | ~10ms |
| 冷数据查询 | < 100ms | ~50ms |
| 跨粒度查询 | < 100ms | ~80ms |

---

## 10. 技术要点

### 10.1 时间窗口对齐

#### 计算方法

给定一个时间戳和粒度，计算其所属窗口。

**示例**:
- 时间戳: `2024-01-26T10:23:45.678Z`
- 粒度: `5m`

**计算**:
```
1. 转换为毫秒: 1706282625678
2. 计算对齐时间: floor(1706282625678 / 300000) * 300000
3. 结果: 1706282400000
4. 转换为时间: 2024-01-26T10:20:00.000Z

窗口范围:
- 开始: 2024-01-26T10:20:00.000Z
- 结束: 2024-01-26T10:25:00.000Z
```

#### 关键点

- 严格对齐，窗口边界固定
- 左闭右开区间: `[start, end)`
- 所有粒度共享相同的对齐逻辑

### 10.2 数据一致性

#### 写入顺序保证

**问题**: 并发写入可能导致顺序错乱

**解决方案**:
1. 单序列写入队列
2. 时间戳单调性检查
3. 使用乐观锁

**流程**:
```
write(dataPoint):
  1. 检查时间戳是否单调递增
  2. 添加到写入队列
  3. 添加到聚合缓冲区
  4. 更新最后写入时间戳
```

#### 幂等性保证

**问题**: 重复写入可能导致数据重复

**解决方案**:
1. 写入前检查
2. 使用唯一键

**流程**:
```
write(dataPoint):
  1. 查找是否已存在
  2. 如果存在，更新而非插入
  3. 如果不存在，插入新数据
```

### 10.3 性能优化

#### 查询缓存

**缓存键**: `seriesId_granularity_startTime_endTime_metrics`

**缓存策略**:
- 最近查询的结果缓存 10 秒
- 热门查询（高命中率）缓存 60 秒
- LRU 淘汰策略
- 内存占用限制

#### 预聚合优化

**策略**:
- 增量更新，避免全量重算
- 累加器合并，支持窗口合并
- 批量持久化，减少 IO

#### 查询优化

**策略**:
- 分层查询，自动路由
- 跨粒度查询自动降级
- 并行查询多层级

### 10.4 资源管理

#### 内存管理

**策略**:
- 限制活跃窗口数量
- 限制缓存大小
- 动态调整

**降级策略**:
- 内存不足时清理缓存
- 减少活跃窗口缓存
- 优先保证实时写入

#### 存储优化

**策略**:
- 批量删除原始数据
- 使用临时表
- 进度可查询

---

## 附录

### A. 预定义粒度列表

| ID | 粒度 | 描述 | 常见用途 |
|----|-------|------|---------|
| 0 | 1m | 1 分钟 | 短期交易、实时监控 |
| 1 | 5m | 5 分钟 | 日内交易分析 |
| 2 | 15m | 15 分钟 | 短期趋势分析 |
| 3 | 30m | 30 分钟 | 中期趋势分析 |
| 4 | 60m | 1 小时 | 日内波段操作 |
| 5 | 120m | 2 小时 | 日内趋势 |
| 6 | 1d | 1 天 | 中长期分析 |
| 7 | 5d | 5 天 | 中期策略 |
| 8 | 20d | 20 天 | 中长期策略 |
| 9 | 120d | 120 天 | 长期趋势 |
| 10 | 250d | 250 天 | 年度分析 |

### B. 聚合指标列表

| 指标名 | 类型 | 描述 | 适用序列 |
|-------|------|------|---------|
| open | 基本 | 周期开始时的值 | CONTINUOUS |
| close | 基本 | 周期结束时的值 | CONTINUOUS |
| high | 基本 | 周期内的最高值 | CONTINUOUS |
| low | 基本 | 周期内的最低值 | CONTINUOUS |
| sum | 统计 | 周期内值的总和 | DISCRETE |
| count | 统计 | 周期内数据点数量 | DISCRETE |
| vwap | 高级 | 成交量加权平均价格 | CONTINUOUS |

### C. 缺失数据处理策略

| 序列类型 | 策略 | 说明 |
|---------|------|------|
| CONTINUOUS | PREVIOUS_CLOSE | 用上一周期的 close 作为当前 open |
| DISCRETE | ZERO | 周期内无交易则值为 0 |

### D. 数据保留策略

| 数据层级 | 粒度 | 保留策略 | 剔除条件 |
|---------|-------|---------|---------|
| Level 0 | < 1m | 临时 | 1m 聚合完成后 + 60 秒缓冲 |
| Level 1 | = 1m | 永久 | 永不剔除 |
| Level 2-N | > 1m | 永久 | 永不剔除 |

---

## 术语表

| 术语 | 英文 | 解释 |
|-----|------|------|
| 聚合粒度 | Granularity | 时间聚合的基本单位 |
| 聚合窗口 | Aggregation Window | 按指定粒度划分的时间区间 |
| 数据点 | Data Point | 最细粒度的原始数据 |
| 聚合点 | Aggregated Point | 聚合窗口的计算结果 |
| 序列 | Series | 同一标识符的所有数据点集合 |
| 最小粒度 | Minimum Granularity | 系统最细的预聚合粒度（1m） |
| 粗粒度 | Coarse Granularity | 大于最小粒度的预聚合粒度 |
| 连续值序列 | Continuous Series | 数据值在时间上连续变化 |
| 离散值序列 | Discrete Series | 数据值表示事件发生的频率 |
| 累加器 | Accumulator | 支持增量更新的数据结构 |
| 预聚合 | Pre-aggregation | 提前计算并存储的聚合结果 |

---

## 变更记录

| 版本 | 日期 | 变更内容 | 作者 |
|-----|------|---------|------|
| 1.0 | 2026-01-26 | 初始版本 | - |

---

## 许可证

本文档为内部设计文档，未经授权不得外传。
